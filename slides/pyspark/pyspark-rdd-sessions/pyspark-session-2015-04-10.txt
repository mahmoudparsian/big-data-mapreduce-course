First session on PySpark

$ cat zfox_data.txt
crazy red fox ran fast
red fox jumped very very high
red fox is very crazy
red fox ran very fast

$ # invoke Interactive PySpark
$ /home/zmp/spark-1.3.0/bin/pyspark
Python 2.6.9 (unknown, Sep  9 2014, 15:05:12) 
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 1.3.0
      /_/

Using Python version 2.6.9 (unknown, Sep  9 2014 15:05:12)
SparkContext available as sc, SQLContext available as sqlCtx.
>>> 
>>> sc
<pyspark.context.SparkContext object at 0x1097ac410>
>>> 
>>> lines = sc.textFile("zfox_data.txt")
>>> 
>>> lines.collect()
[
 u'crazy red fox ran fast', 
 u'red fox jumped very very high', 
 u'red fox is very crazy', 
 u'red fox ran very fast'
]
>>> 
>>> lines.count()
4
>>> 
>>> words = lines.flatMap(lambda x: x.split(' '))
>>> 
>>> words.collect()
[
 u'crazy', 
 u'red', 
 u'fox', 
 u'ran', 
 u'fast', 
 u'red', 
 u'fox', 
 u'jumped', 
 u'very', 
 u'very', 
 u'high', 
 u'red', 
 u'fox', 
 u'is', 
 u'very', 
 u'crazy', 
 u'red', 
 u'fox', 
 u'ran', 
 u'very', 
 u'fast'
]
>>> 
>>> words.count()
21
>>> 
>>> ones = words.map(lambda x: (x, 1))
>>> 
>>> ones.collect()
[
 (u'crazy', 1), 
 (u'red', 1), 
 (u'fox', 1), 
 (u'ran', 1), 
 (u'fast', 1), 
 (u'red', 1), 
 (u'fox', 1), 
 (u'jumped', 1), 
 (u'very', 1), 
 (u'very', 1), 
 (u'high', 1), 
 (u'red', 1), 
 (u'fox', 1), 
 (u'is', 1), 
 (u'very', 1), 
 (u'crazy', 1), 
 (u'red', 1), 
 (u'fox', 1), 
 (u'ran', 1), 
 (u'very', 1), 
 (u'fast', 1)
]
>>> 
>>> counts = ones.reduceByKey(lambda x, y: x + y)
>>> 
>>> counts.collect()
[
 (u'crazy', 2), 
 (u'ran', 2), 
 (u'is', 1), 
 (u'fox', 4), 
 (u'fast', 2), 
 (u'high', 1), 
 (u'very', 4), 
 (u'red', 4), 
 (u'jumped', 1)
]
>>> 
